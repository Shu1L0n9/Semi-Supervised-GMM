# Semi-Supervised Gaussian Mixture Model (SGMM) Implementation

This project provides unofficial implementations of Semi-Supervised Gaussian from References.

## References

Miller, David J, and Hasan Uyar. â€œA Mixture of Experts Classifier with Learning Based on Both Labelled and Unlabelled Data.â€ In Advances in Neural Information Processing Systems, Vol. 9. MIT Press, 1996.

## ğŸ“š Citation

You can cite the SGMM method proposed by Miller and Uyar using the following BibTeX entry:

```bibtex
@inproceedings{miller1996mixture,
  title     = {A mixture of experts classifier with learning based on both labelled and unlabelled data},
  author    = {Miller, David J. and Uyar, Hasan},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {9},
  year      = {1996}
}
```

## Project Structure

```plaintext
Semi-Supervised GMM/
â”‚
â”œâ”€â”€ matlab/                         # MATLAB implementation
â”‚   â”œâ”€â”€ test_sgmm.m                # SGMM basic functionality test
â”‚   â”œâ”€â”€ synthetic_data_classification.m # Synthetic data classification experiment
â”‚   â”œâ”€â”€ gmm/                       # Standard GMM implementation (for comparison and data generation)
â”‚   â”‚   â”œâ”€â”€ gmm.m                  # GMM core functions
â”‚   â”‚   â”œâ”€â”€ gmmsamp.m              # GMM sampling functions
â”‚   â”‚   â””â”€â”€ Â·Â·Â·                    # Other GMM related functions
â”‚   â””â”€â”€ sgmm/                      # Semi-supervised GMM implementation
â”‚       â”œâ”€â”€ sgmminit.m             # SGMM initialization
â”‚       â”œâ”€â”€ sgmmem.m               # SGMM EM algorithm
â”‚       â”œâ”€â”€ sgmmpred.m             # SGMM prediction
â”‚       â”œâ”€â”€ sgmmpost.m             # SGMM posterior probability calculation
â”‚       â””â”€â”€ Â·Â·Â·                    # Other SGMM related functions
â”‚
â”œâ”€â”€ python/                         # Python implementation
â”‚   â”œâ”€â”€ sgmm_core.py               # SGMM core algorithm implementation
â”‚   â”œâ”€â”€ train_sgmm.py              # SGMM training script
â”‚   â””â”€â”€ utils.py                   # Utility functions
â”‚
â”œâ”€â”€ data/                           # Dataset directory
â”‚   â”œâ”€â”€ mnist/                     # MNIST dataset (prepare yourself)
â”‚   â””â”€â”€ synthetic_data/            # Synthetic dataset
â”‚       â”œâ”€â”€ synthetic_data_train.csv
â”‚       â””â”€â”€ synthetic_data_test.csv
â”‚
â””â”€â”€ README.md                      # Project documentation
```

## Two Implementation Versions

### MATLAB Version
- **Features**: Direct implementation of the original paper algorithm, fully following the mathematical formulas in the paper
- **Advantages**: Precise mathematical calculations, efficient matrix operations, suitable for algorithm research and validation
- **Use Cases**: Academic research, algorithm validation, small-scale experiments

### Python Version  
- **Features**: Optimized implementation based on modern machine learning frameworks
- **Advantages**: High code readability, easy to extend, supports large-scale data processing
- **Use Cases**: Practical applications, large-scale experiments, engineering projects

## Algorithm Overview

The Semi-Supervised Gaussian Mixture Model (SGMM) is a mixture of experts classifier that can learn from both labeled and unlabeled data simultaneously. The core idea of this method is:

- **Labeled Data**: Used for supervised learning to directly optimize classification performance
- **Unlabeled Data**: Used for unsupervised learning through EM algorithm to improve model density estimation
- **Hybrid Learning**: Combines information from both data types to improve classification accuracy and generalization ability

Supports three types of covariance matrices:
- `spherical`: Spherical covariance (independent components with equal variance)
- `diag`: Diagonal covariance (independent components with unequal variance)
- `full`: Full covariance (allows correlation between components)

## Experiment Scripts

### MATLAB Experiments

#### 1. test_sgmm.m
Basic functionality verification experiment. Uses GMM to generate simple synthetic datasets to validate the correctness of SGMM core functions (`sgmminit`, `sgmmem`, etc.). Supports testing of three covariance types.

#### 2. synthetic_data_classification.m
Synthetic data classification experiment. Performs classification on dollar sign-shaped synthetic data, primarily evaluating SGMM classification performance using full covariance matrices.

### Python Experiments

#### 1. train_sgmm.py
SGMM training script providing complete training process and parameter settings.

#### 2. sgmm_core.py
Contains core SGMM algorithm implementation, including initialization, EM algorithm updates, and prediction functions.

## Quick Start

### MATLAB Version

#### Requirements
- MATLAB R2016b or higher

#### Steps
1. Open the project directory in MATLAB
2. Add subfolders to MATLAB path:

```matlab
addpath('matlab/sgmm');
addpath('matlab/gmm');
addpath('data');
```

3. Run basic verification experiment:

```matlab
cd matlab
test_sgmm
```

4. Run synthetic data classification experiment:

```matlab
synthetic_data_classification
```

### Python Version

#### Requirements
- Python 3.7 or higher
- Dependencies: NumPy, SciPy, scikit-learn, matplotlib, etc.

#### Steps
1. Install dependencies:

```bash
pip install numpy scipy scikit-learn matplotlib pandas
```

2. Run training script:

```bash
cd python
python train_sgmm.py
```

## License

This project is for academic research use only.